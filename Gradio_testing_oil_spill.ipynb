{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Codamaze/OilSpillDetection/blob/main/Gradio_testing_oil_spill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI9XMa07ZiqD",
        "outputId": "d5c80ae5-f9a2-41b1-a889-fcf616f213ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fd_QoVK3aUTK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from albumentations import Compose, RandomCrop, HorizontalFlip, Rotate, GaussNoise, RandomBrightnessContrast, HueSaturationValue\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define color-to-class mapping (RGB values for each class)\n",
        "COLOR_MAP = [\n",
        "    [0, 0, 0],        # Class 0: Black\n",
        "    [0, 255, 255],    # Class 1: Cyan\n",
        "    [153, 76, 0],      # Class 2: Brown\n",
        "    [255, 0, 0],     # Class 3: Red\n",
        "    [0, 153, 0],      # Class 4: Green\n",
        "]\n",
        "\n",
        "def process_mask(rgb_mask, colormap):\n",
        "    \"\"\"\n",
        "    Converts an RGB mask to a one-hot encoded class mask using the provided colormap.\n",
        "    Args:\n",
        "        rgb_mask: RGB mask (H, W, 3)\n",
        "        colormap: List of RGB values for each class.\n",
        "    Returns:\n",
        "        One-hot encoded mask (H, W, num_classes)\n",
        "    \"\"\"\n",
        "    output_mask = []\n",
        "    for i, color in enumerate(colormap):\n",
        "        cmap = np.all(np.equal(rgb_mask, color), axis=-1).astype(np.uint8)  # Check if pixel matches color and cast to uint8\n",
        "        output_mask.append(cmap)\n",
        "\n",
        "    output_mask = np.stack(output_mask, axis=-1)  # Stack the individual class masks to create a one-hot mask\n",
        "    return output_mask\n",
        "\n",
        "# Define the augmentation pipeline\n",
        "transform = Compose([\n",
        "    RandomCrop(height=256, width=256),             # Random cropping\n",
        "    # HorizontalFlip(p=0.5),                         # Horizontal flipping\n",
        "    # Rotate(limit=30, p=0.5),                       # Random rotation\n",
        "    HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.4),  # Adjust colors slightly\n",
        "    RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),  # Mild adjustments\n",
        "    ToTensorV2(),                      # Convert to PyTorch tensors\n",
        "])\n",
        "\n",
        "# Dataset class\n",
        "class MultiClassOilSpillDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, color_mapping, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.color_mapping = color_mapping\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # Read unchanged for SAR images\n",
        "\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[idx].replace(\".jpg\", \".png\"))\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
        "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Ensure RGB format\n",
        "\n",
        "        ''' to apply visulaisation\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(\"Raw Image\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(mask_rgb)\n",
        "        plt.title(\"Raw Mask\")\n",
        "\n",
        "        plt.show()'''\n",
        "\n",
        "        # Load image and mask\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # Load SAR image as is\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)      # Load mask as RGB\n",
        "\n",
        "        # Validate data\n",
        "        if image is None or mask is None:\n",
        "            raise FileNotFoundError(f\"Missing file: {img_path} or {mask_path}\")\n",
        "\n",
        "        # Normalize SAR image dynamically\n",
        "        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "        image = image.astype(np.float32) # Cast the image to float32\n",
        "\n",
        "\n",
        "        # Resize image and mask\n",
        "        image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # Convert mask to class indices\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "        processed_mask = process_mask(mask, self.color_mapping)\n",
        "\n",
        "        # Convert one-hot encoded mask to class indices\n",
        "        processed_mask = np.argmax(processed_mask, axis=-1)\n",
        "\n",
        "\n",
        "        # Apply augmentations if specified\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=processed_mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "            image = np.clip(image, 0, 1)\n",
        "\n",
        "        return image, mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QGu65BJyawpO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision.models.resnet import resnet18\n",
        "from torchvision.models.resnet import ResNet18_Weights\n",
        "\n",
        "\n",
        "class UNetResNet18(nn.Module):\n",
        "    def __init__(self, input_channels, IMG_CLASSES):\n",
        "        super(UNetResNet18, self).__init__()\n",
        "\n",
        "        # ResNet18 as the encoder (feature extractor)\n",
        "        resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "        # Remove the fully connected layer and the classification layer\n",
        "        self.encoder = nn.Sequential(\n",
        "            resnet.conv1,  # c1\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1, # c2\n",
        "            resnet.layer2, # c3\n",
        "            resnet.layer3, # c4\n",
        "            resnet.layer4  # c5\n",
        "        )\n",
        "\n",
        "        # Decoder blocks (matching the original U-Net structure)\n",
        "        self.upconv4 = self.upconv_block(512, 256)\n",
        "        self.upconv3 = self.upconv_block(256 + 256, 128)  # Concatenate with c4\n",
        "        self.upconv2 = self.upconv_block(128 + 128, 64)   # Concatenate with c3\n",
        "        self.upconv1 = self.upconv_block(64 + 64, 32)     # Concatenate with c2\n",
        "\n",
        "        # Final convolution to output IMG_CLASSES channels\n",
        "        self.final_conv = nn.Conv2d(32, IMG_CLASSES, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder forward pass (ResNet18 backbone)\n",
        "        c1 = self.encoder[0:4](x)    # Conv1 to maxpool\n",
        "        c2 = self.encoder[4](c1)     # Layer1 (64 channels -> 64)\n",
        "        c3 = self.encoder[5](c2)     # Layer2 (128 channels -> 128)\n",
        "        c4 = self.encoder[6](c3)     # Layer3 (256 channels -> 256)\n",
        "        c5 = self.encoder[7](c4)     # Layer4 (512 channels -> 512)\n",
        "\n",
        "        # Decoder forward pass (Upsample and concatenate with encoder layers)\n",
        "        u4 = self.upconv4(c5)\n",
        "        u3 = self.upconv3(torch.cat([u4, c4], dim=1))  # Skip connection with c4\n",
        "        u2 = self.upconv2(torch.cat([u3, c3], dim=1))  # Skip connection with c3\n",
        "        u1 = self.upconv1(torch.cat([u2, c2], dim=1))  # Skip connection with c2\n",
        "\n",
        "        # Final output layer\n",
        "        out = self.final_conv(u1)\n",
        "        return out\n",
        "\n",
        "    def upconv_block(self, in_channels, out_channels):\n",
        "        \"\"\" Upsampling block (ConvTranspose + Conv2d) \"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kFPFMDUJbAD_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import mobilenet_v3_large\n",
        "from torchvision.models.mobilenetv3 import MobileNet_V3_Large_Weights\n",
        "\n",
        "# Atrous Spatial Pyramid Pooling (ASPP) module\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ASPP, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.gn1 = nn.GroupNorm(16, out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, dilation=1, bias=False)\n",
        "        self.gn2 = nn.GroupNorm(16, out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, dilation=6, padding=6, bias=False)\n",
        "        self.gn3= nn.GroupNorm(16, out_channels)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, dilation=12, padding=12, bias=False)\n",
        "        self.gn4= nn.GroupNorm(16, out_channels)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=3, dilation=18, padding=18, bias=False)\n",
        "        self.gn5= nn.GroupNorm(16, out_channels)\n",
        "\n",
        "        self.output = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1, bias=False)\n",
        "        self.out_gn= nn.GroupNorm(16, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.size(2), x.size(3)\n",
        "\n",
        "        y1 = self.avg_pool(x)\n",
        "        y1 = self.conv1(y1)\n",
        "        y1 = self.gn1(y1)\n",
        "        y1 = self.relu(y1)\n",
        "        y1 = F.interpolate(y1, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        y2 = self.conv2(x)\n",
        "        y2 = self.gn2(y2)\n",
        "        y2 = self.relu(y2)\n",
        "\n",
        "        y3 = self.conv3(x)\n",
        "        y3 = self.gn3(y3)\n",
        "        y3 = self.relu(y3)\n",
        "\n",
        "        y4 = self.conv4(x)\n",
        "        y4 = self.gn4(y4)\n",
        "        y4 = self.relu(y4)\n",
        "\n",
        "        y5 = self.conv5(x)\n",
        "        y5 = self.gn5(y5)\n",
        "        y5 = self.relu(y5)\n",
        "\n",
        "        y = torch.cat([y1, y2, y3, y4, y5], dim=1)\n",
        "        y = self.output(y)\n",
        "        y = self.out_gn(y)\n",
        "        return self.relu(y)\n",
        "\n",
        "\n",
        "# DeepLabV3+ module\n",
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DeepLabV3Plus, self).__init__()\n",
        "        self.encoder = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT).features\n",
        "\n",
        "        # Extract intermediate layers\n",
        "        self.low_level_idx = 3  # Low-level features from MobileNetV3\n",
        "        self.high_level_idx = 16  # High-level features from MobileNetV3\n",
        "\n",
        "        self.aspp = ASPP(in_channels=160, out_channels=256) # 160 channels for MobileNetV3 model\n",
        "        # Low-level feature projection\n",
        "        self.low_level_conv = nn.Conv2d(24, 48, kernel_size=1, bias=False)\n",
        "        self.low_level_gn = nn.GroupNorm(16, 48)\n",
        "        self.low_level_relu = nn.ReLU()\n",
        "\n",
        "        # Decoder\n",
        "        self.concat_conv1 = nn.Conv2d(256 + 48, 256, kernel_size=3, padding=1, bias=False)\n",
        "        self.concat_gn1 = nn.GroupNorm(32, 256)\n",
        "        self.concat_relu1 = nn.ReLU()\n",
        "\n",
        "        self.concat_conv2 = nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False)\n",
        "        self.concat_gn2= nn.GroupNorm(32, 256)\n",
        "        self.concat_relu2 = nn.ReLU()\n",
        "\n",
        "        self.final_conv = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.size(2), x.size(3)\n",
        "\n",
        "        # Encoder\n",
        "        low_level_features = self.encoder[:self.low_level_idx](x)\n",
        "        high_level_features = self.encoder[:self.high_level_idx](x)\n",
        "\n",
        "        # ASPP\n",
        "        x = self.aspp(high_level_features)\n",
        "        x = F.interpolate(x, size=(h // 4, w // 4), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        # Low-level features\n",
        "        low_level_features = self.low_level_conv(low_level_features)\n",
        "        low_level_features = self.low_level_gn(low_level_features)\n",
        "        low_level_features = self.low_level_relu(low_level_features)\n",
        "\n",
        "        # Concatenate low-level and ASPP features\n",
        "        x = torch.cat([x, low_level_features], dim=1)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.concat_conv1(x)\n",
        "        x = self.concat_gn1(x)\n",
        "        x = self.concat_relu1(x)\n",
        "\n",
        "        x = self.concat_conv2(x)\n",
        "        x = self.concat_gn2(x)\n",
        "        x = self.concat_relu2(x)\n",
        "\n",
        "        # Upsample to original size\n",
        "        x = F.interpolate(x, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        # Final classification layer\n",
        "        x = self.final_conv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "teB5auRxbDav"
      },
      "outputs": [],
      "source": [
        "from albumentations import Compose, RandomCrop, HorizontalFlip, Rotate, GaussNoise, RandomBrightnessContrast, HueSaturationValue\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "transform = Compose([\n",
        "    RandomCrop(height=256, width=256),             # Random cropping\n",
        "    HorizontalFlip(p=0.5),                         # Horizontal flipping\n",
        "    Rotate(limit=30, p=0.5),                       # Random rotation\n",
        "    HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.4),  # Adjust colors slightly\n",
        "    RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),  # Mild adjustments\n",
        "    ToTensorV2(),                      # Convert to PyTorch tensors\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt4KgW-bbkSe",
        "outputId": "65d05bb0-8b5d-4db6-f3f6-6e93962e60c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 92.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepLabV3Plus(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (16): Conv2dNormActivation(\n",
              "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "  )\n",
              "  (aspp): ASPP(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (conv1): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (gn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
              "    (relu): ReLU()\n",
              "    (conv2): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (gn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
              "    (conv3): Conv2d(160, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
              "    (gn3): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
              "    (conv4): Conv2d(160, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "    (gn4): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
              "    (conv5): Conv2d(160, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
              "    (gn5): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
              "    (output): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (out_gn): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
              "  )\n",
              "  (low_level_conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (low_level_gn): GroupNorm(16, 48, eps=1e-05, affine=True)\n",
              "  (low_level_relu): ReLU()\n",
              "  (concat_conv1): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (concat_gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "  (concat_relu1): ReLU()\n",
              "  (concat_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (concat_gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "  (concat_relu2): ReLU()\n",
              "  (final_conv): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load your models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate your models\n",
        "unet_model = UNetResNet18(input_channels=3, IMG_CLASSES=5)\n",
        "deeplab_model = DeepLabV3Plus(num_classes=5)\n",
        "\n",
        "\n",
        "unet_model.load_state_dict(torch.load(\"/content/drive/MyDrive/unetresnet18_100.pth\", map_location='cpu'))\n",
        "unet_model.to(device)\n",
        "deeplab_model.load_state_dict(torch.load(\"/content/drive/MyDrive/deeplabv3+_mobilentv3_50.pth\", map_location='cpu'))\n",
        "deeplab_model.to(device)\n",
        "\n",
        "unet_model.eval()\n",
        "deeplab_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "VDJLj_vfcnEO",
        "outputId": "63c23dc5-1c0b-44ac-dfe5-47eb3e4be00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ab50a944f1af76cac6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ab50a944f1af76cac6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ab50a944f1af76cac6.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from albumentations import Compose, HueSaturationValue, RandomBrightnessContrast, ToTensorV2\n",
        "\n",
        "# Albumentations Transform (Your Original Preprocessing)\n",
        "transform = Compose([\n",
        "    HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.4),\n",
        "    RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "COLOR_MAP = [\n",
        "    [0, 0, 0],        # Class 0: Black\n",
        "    [0, 255, 255],    # Class 1: Cyan\n",
        "    [153, 76, 0],     # Class 2: Brown\n",
        "    [255, 0, 0],      # Class 3: Red\n",
        "    [0, 153, 0],      # Class 4: Green\n",
        "]\n",
        "\n",
        "def segment_image(image):\n",
        "    \"\"\" Runs segmentation using both DeepLabV3+ and U-Net. \"\"\"\n",
        "\n",
        "    image = np.array(image)\n",
        "    image_normalized = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "    image_normalized = image_normalized.astype(np.float32)\n",
        "    image_resized = cv2.resize(image_normalized, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    augmented = transform(image=image_resized)\n",
        "    input_tensor = augmented['image'].unsqueeze(0).to(device).float()\n",
        "\n",
        "    # Get predictions from both models\n",
        "    def get_prediction(model,target_size=(256,256)):\n",
        "        with torch.no_grad():\n",
        "            pred = model(input_tensor)\n",
        "            pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "        pred_mask = np.zeros((pred.shape[0], pred.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "        for class_idx, color in enumerate(COLOR_MAP):\n",
        "            pred_mask[pred == class_idx] = color\n",
        "\n",
        "        pred_mask_resized = cv2.resize(pred_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        return Image.fromarray(pred_mask_resized)\n",
        "        # return Image.fromarray(pred_mask)\n",
        "\n",
        "    deeplab_pred = get_prediction(deeplab_model)\n",
        "    unet_pred = get_prediction(unet_model)\n",
        "\n",
        "    return deeplab_pred, unet_pred\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=segment_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"DeepLabV3+ Prediction\", type=\"pil\"),\n",
        "        gr.Image(label=\"U-Net Prediction\", type=\"pil\")\n",
        "    ],\n",
        "    title=\"Oil Spill Detection\",\n",
        "    description=\"Upload an image to see segmentation results from DeepLabV3+ and U-Net.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "\n",
        "iface.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UND5X4Oz3VN-",
        "outputId": "81718fbd-d636-4fa7-cbce-788670a28682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.119.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObH6GeHWcoNIijcgFDBnhf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}